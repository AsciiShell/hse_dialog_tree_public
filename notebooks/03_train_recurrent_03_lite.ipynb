{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33156,
     "status": "ok",
     "timestamp": 1619875122558,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "y0DILoQq0gVh",
    "outputId": "b6e5517f-57ab-4dcc-d8bd-a35c9e4347a3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/Shareddrives/Диплом Дерево диалогов/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "186xsvnqwtt1ayeexx77rg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1619875305125,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "kWgQkKLT0ehs",
    "outputId": "65634390-8abe-4b52-ad78-af5f1737a2e4"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from experiment_collection import ExperimentCollectionRemote, Experiment\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from hse_dialog_tree.utils.cpu import get_processor_info\n",
    "from hse_dialog_tree.utils.files import load_pickle\n",
    "\n",
    "LANG = 'rus'\n",
    "print(get_processor_info())\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = layers.MultiHeadAttention(num_heads, d_model)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training):\n",
    "        attn_output = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1619875130201,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "CfXrZhzn0eh2"
   },
   "outputs": [],
   "source": [
    "exps = ExperimentCollectionRemote('HOST',  \n",
    "                                  '03_recurrent3',\n",
    "                                  'TOKEN', \n",
    "                                 credentials=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25931,
     "status": "ok",
     "timestamp": 1619875155759,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "pYVKXLE80eh4"
   },
   "outputs": [],
   "source": [
    "X_lstm_train, y_lstm_train, X_lstm_test, y_lstm_test, cl_lstm_train, cl_lstm_test = load_pickle('lite/03_train_recurrent3.pkl.zip')\n",
    "cluster_model_kmeans = load_pickle('steps/03_kmeans/kmeans_v2_044.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1619875475489,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "Gz--jplA0eh5"
   },
   "outputs": [],
   "source": [
    "def make_experiment(model_creator, model_descr, exps, epochs=3):\n",
    "    for loss in ['CosineSimilarity', 'MeanSquaredError']:\n",
    "    # for loss in ['MeanSquaredError']:\n",
    "    # for loss in ['CosineSimilarity']:\n",
    "        model = model_creator(loss)\n",
    "        for epoch in range(epochs):\n",
    "            h = model.fit(X_lstm_train, y_lstm_train, \n",
    "                          validation_data=(X_lstm_test, y_lstm_test), \n",
    "                          epochs=epoch + 1, initial_epoch=epoch, verbose=1)\n",
    "\n",
    "            predict_lstm_train = model.predict(X_lstm_train, batch_size=64)\n",
    "            predict_lstm_test = model.predict(X_lstm_test, batch_size=64)\n",
    "            predict_lstm_train_cluster = cluster_model_kmeans.predict(predict_lstm_train)\n",
    "            predict_lstm_test_cluster = cluster_model_kmeans.predict(predict_lstm_test)\n",
    "\n",
    "            r = []\n",
    "            p = []\n",
    "            for predict, true in zip(predict_lstm_train_cluster, cl_lstm_train):\n",
    "                r.append(predict in true)\n",
    "                pos = np.where(true == predict)[0]\n",
    "                if len(pos) > 0:\n",
    "                    p.append(pos.min())\n",
    "                else:\n",
    "                    p.append(len(true + 1))\n",
    "            acc_train = np.mean(r)\n",
    "            pos_train = np.mean(p)\n",
    "\n",
    "            r = []\n",
    "            p = []\n",
    "            for predict, true in zip(predict_lstm_test_cluster, cl_lstm_test):\n",
    "                r.append(predict in true)\n",
    "                pos = np.where(true == predict)[0]\n",
    "                if len(pos) > 0:\n",
    "                    p.append(pos.min())\n",
    "                else:\n",
    "                    p.append(len(true + 1))\n",
    "            acc_test = np.mean(r)\n",
    "            pos_test = np.mean(p)\n",
    "\n",
    "            exp = Experiment(uuid.uuid4().__str__(), \n",
    "                     {\n",
    "                         'architecture': model_descr,\n",
    "                         'loss': loss,\n",
    "                         'epochs': epoch + 1,\n",
    "                     },\n",
    "                    {\n",
    "                        'cos': h.history['cosine_similarity'][0],\n",
    "                        'mse': h.history['MSE'][0],\n",
    "                        'acc': acc_train,\n",
    "                        'pos': pos_train,\n",
    "                        'val_cos': h.history['val_cosine_similarity'][0],\n",
    "                        'val_mse': h.history['val_MSE'][0],\n",
    "                        'val_acc': acc_test,\n",
    "                        'val_pos': pos_test,\n",
    "                    }\n",
    "                    )\n",
    "            exps.add_experiment(exp)\n",
    "            del predict_lstm_train, predict_lstm_test, predict_lstm_train_cluster, predict_lstm_test_cluster, exp\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190406,
     "status": "ok",
     "timestamp": 1619875669111,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "C9azsBpMFaGO",
    "outputId": "a81842f7-fba5-4e73-b711-e7522b615238"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.LSTM(128)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'LSTM128 BN ReLU Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240147,
     "status": "ok",
     "timestamp": 1619875934746,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "qSQMcDV8FaEN",
    "outputId": "6371b3a0-88a7-4582-f6f6-2bf9932b1471"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiLSTM128 BN ReLU Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 793506,
     "status": "ok",
     "timestamp": 1619876488515,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "9g6xOUZGFaCY",
    "outputId": "1e781530-71fc-47ba-8ed8-08701ba49492"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.LSTM(512)(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'LSTM512', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1480193,
     "status": "ok",
     "timestamp": 1619877175555,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "-4Pea3Q0FaAD",
    "outputId": "7aabf1ed-6410-4a46-8c61-74bbc87e3cf9"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.LSTM(256))(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiLSTM256', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1997616,
     "status": "ok",
     "timestamp": 1619877693329,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "9Jd67Kb4FZ-T",
    "outputId": "437754da-fed6-459a-ed7a-d77c9db1f8dd"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.GRU(512)(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'GRU512', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2645778,
     "status": "ok",
     "timestamp": 1619878341838,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "zDOqlL3vFZ79",
    "outputId": "0ab8ca1f-b96d-4227-815a-30bcf54981c0"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.GRU(256))(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiGRU256', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2816420,
     "status": "ok",
     "timestamp": 1619878512823,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "ha5QFRIHFZ59",
    "outputId": "55d403d6-ab9b-45e2-d8f2-48b65fa4edb3"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    def self_attention(x, f=512, k=1):\n",
    "        x = layers.Conv1D(filters=f, kernel_size=k, padding='same')(x)\n",
    "        x = layers.Attention(use_scale=True)([x, x])\n",
    "        return x\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = self_attention(x, 64, 1)\n",
    "    x = self_attention(x, 128, 2)\n",
    "    x = self_attention(x, 512, 3)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'SA(f,k)=(conv(f,k) Attention) SA(64,1) SA(128,2) SA(512,3) GAP', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3000096,
     "status": "ok",
     "timestamp": 1619878696855,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "EOoFYdUcFZ3s",
    "outputId": "64feaeaf-5bb3-4f9c-ea92-dc005b607ef0"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    def self_attention(x, f=512, k=1):\n",
    "        x = layers.Conv1D(filters=f, kernel_size=k, padding='same')(x)\n",
    "        x = layers.Attention(use_scale=True)([x, x])\n",
    "        return x\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = self_attention(x, 64, 5)\n",
    "    x = self_attention(x, 128, 3)\n",
    "    x = self_attention(x, 512, 2)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'SA(f,k)=(conv(f,k) Attention) SA(64,5) SA(128,3) SA(512,2) GAP', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3226352,
     "status": "ok",
     "timestamp": 1619878923460,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "t-KOP1w0FZ1b",
    "outputId": "aa42efd8-e0ab-4fb2-d160-ee460d4da305"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Attention(use_scale=True)([x, x]) \n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiLSTM(128) Drop0.1 Dense128 Relu Attention Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3460330,
     "status": "ok",
     "timestamp": 1619879157781,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "LrU4MUBoFZzi",
    "outputId": "d2b37ac7-8cf9-4408-abd4-f27b5af818bd"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x]) \n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiLSTM(128) Drop0.1 Dense128 Relu Attention Attention Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3700503,
     "status": "ok",
     "timestamp": 1619879398273,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "Deofh6iLFZw2",
    "outputId": "53824c88-271a-46da-ec20-451fc1049650"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x]) \n",
    "    x = layers.Attention(use_scale=True)([x, x]) \n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'BiLSTM(128) Drop0.1 Dense128 Relu Attention Attention Attention Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3930987,
     "status": "ok",
     "timestamp": 1619879629093,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "2yud0K6GFZul",
    "outputId": "41a26716-2cb9-4350-a053-dacacab7da53"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention BiLSTM(128) Drop0.1 Dense128 Relu Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4165806,
     "status": "ok",
     "timestamp": 1619879864252,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "GSE8LAFoFZsg",
    "outputId": "bd2be622-4eb5-4112-8938-c54884566b6d"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention Attention BiLSTM(128) Drop0.1 Dense128 Relu Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4413211,
     "status": "ok",
     "timestamp": 1619880111987,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "kI-8HsHxFZqh",
    "outputId": "50445bc8-2a3f-4ff0-c0c6-b0f454466992"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention Attention Attention BiLSTM(128) Drop0.1 Dense128 Relu Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4643899,
     "status": "ok",
     "timestamp": 1619880342993,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "IYfvNKGZFZoY",
    "outputId": "3b212ace-b50b-48ae-e2b3-f9b968225e75"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention BiLSTM(128) Drop0.1 Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4884318,
     "status": "ok",
     "timestamp": 1619880583731,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "YA5Uk2jLFZmh",
    "outputId": "4a9809a4-dcec-4a70-9250-5707331f1187"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention Attention BiLSTM(128) Drop0.1 Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5130139,
     "status": "ok",
     "timestamp": 1619880829879,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "-p6NMzlwFZkx",
    "outputId": "3813de19-a55a-438d-e143-17c31764a6c1"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Attention(use_scale=True)([x, x])\n",
    "    x = layers.Bidirectional(layers.LSTM(128,))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'Attention Attention Attention BiLSTM(128) Drop0.1 Dense512', exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6420037,
     "status": "ok",
     "timestamp": 1619882120101,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "Ynh5CDLaFZi6",
    "outputId": "b055e84e-b43b-4c37-acc0-305b22d3f866"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = EncoderLayer(512, 16, 8)(x)     \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'EncoderLayer(512,16,8) GAP', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10800511,
     "status": "ok",
     "timestamp": 1619886500891,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "0mhUVOBPFZgl",
    "outputId": "bede00a8-8412-4184-b9e6-b15895a6abc2"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = EncoderLayer(512, 16, 8)(x) \n",
    "    x = EncoderLayer(512, 16, 8)(x) \n",
    "    x = EncoderLayer(512, 16, 8)(x) \n",
    "    x = EncoderLayer(512, 16, 8)(x)     \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'EncoderLayer(512,16,8)x4 GAP', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10800182,
     "status": "ok",
     "timestamp": 1619886500893,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "_1rAntu1t3cE"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = EncoderLayer(512, 16, 4)(x)     \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'EncoderLayer(512,16,4) GAP', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286954,
     "status": "ok",
     "timestamp": 1619887789758,
     "user": {
      "displayName": "Kak TyC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCmo0EpyeZ3sIs-leTsI0Lv6X5VwFJxZRz6bp76Q=s64",
      "userId": "10975181951625505822"
     },
     "user_tz": -180
    },
    "id": "1-qLe06LPPTL",
    "outputId": "cb71b29b-7237-45aa-840a-1091d2fae9b7"
   },
   "outputs": [],
   "source": [
    "def make_model(loss):\n",
    "    inp = layers.Input(shape=(None, 512))\n",
    "    x = inp\n",
    "    x = EncoderLayer(512, 16, 12)(x)     \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x, name='03_recurrent')\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['CosineSimilarity', 'MSE'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "make_experiment(make_model, 'EncoderLayer(512,16,12) GAP', exps, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwisWsEI423q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03_train_recurrent_03_lite3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "21bad8dc-18cc-475e-b953-a42d85d7ad5e"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
