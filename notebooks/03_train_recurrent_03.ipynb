{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "186xsvnqwtt1ayeexx77rg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel64 Family 6 Model 142 Stepping 9, GenuineIntel x 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import   Dense\n",
    "\n",
    "from hse_dialog_tree.kmeans_names import get_names\n",
    "from hse_dialog_tree.utils.cpu import get_processor_info\n",
    "from hse_dialog_tree.utils.files import load_pickle, dump_pickle\n",
    "from hse_dialog_tree.text_vectorizers import TfUniversalSentenceEncoder\n",
    "\n",
    "LANG = 'rus'\n",
    "print(get_processor_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentence_encoder = TfUniversalSentenceEncoder('Z:/Общие диски/Диплом Дерево диалогов/models/universal-sentence-encoder-multilingual-large_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "5oyru4nzjelueygz2331c"
   },
   "outputs": [],
   "source": [
    "dramas = load_pickle(f'Z:/Общие диски/Диплом Дерево диалогов/data/{LANG}/content_all.pkl.zip')\n",
    "\n",
    "dramas_texts = []\n",
    "for k, v in dramas.items():\n",
    "    dramas_texts.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "zl0rkdssnb8xe2s0oq4959"
   },
   "outputs": [],
   "source": [
    "vectors = load_pickle(f'Z:/Общие диски/Диплом Дерево диалогов/data/{LANG}/02_vectors_v2.pkl.zip')\n",
    "sentence_to_vector = load_pickle(f'Z:/Общие диски/Диплом Дерево диалогов/data/{LANG}/02_sentence_to_vector_v2.pkl.zip')\n",
    "\n",
    "cluster_model_kmeans = load_pickle('Z:/Общие диски/Диплом Дерево диалогов/steps/03_kmeans/kmeans_v2_044.pkl.zip')\n",
    "cluster_names = get_names(cluster_model_kmeans)\n",
    "cluster_names = {\n",
    "        0: 'Благодарность, радость, приветствие',\n",
    "        1: 'Короткая нейтральная фраза',\n",
    "        2: 'Ответ',\n",
    "        3: 'Односложное восклицание',\n",
    "        4: 'Мысли, рассуждение',\n",
    "        5: 'Риторический вопрос, вопрос, порицание',\n",
    "        6: 'Объяснение, пояснение',\n",
    "        7: 'Негативное восклицание',\n",
    "        8: 'Место, направление',\n",
    "        9: 'Просьба, мольба',\n",
    "        10: 'Обращение, мудрые изречения',\n",
    "        11: 'Просьба уйти',\n",
    "        12: 'Вопрос, предложение с \"как\"',\n",
    "        13: 'Краткий ответ',\n",
    "        14: 'Воля, честь, отвага',\n",
    "        15: 'Небольшое повествование',\n",
    "        16: 'Суждение',\n",
    "        17: '\"Знаю\"',\n",
    "        18: '\"Хорошо\", \"молодец\"',\n",
    "        19: 'Короткий вопрос',\n",
    "        20: 'Повествование, высокий слог',\n",
    "        21: 'Думать, вспомнить',\n",
    "        22: 'Личная фраза (я, ты, мы)',\n",
    "        23: 'Смерть',\n",
    "        24: 'Царь',\n",
    "        25: 'Хозяин, барин, сударь',\n",
    "        26: 'Смотреть, видеть',\n",
    "        27: 'Короткий вопрос (кто, что, как)',\n",
    "        28: 'Восклицание с порицанием',\n",
    "        29: 'Отрицание',\n",
    "        30: 'Обращения',\n",
    "        31: 'Отец, сын',\n",
    "        32: 'Испуг, страх',\n",
    "        33: 'Нейтральная фраза',\n",
    "        34: 'О семье (брат/сестра/дядя/дед)',\n",
    "        35: 'Короткая фраза с многоточием',\n",
    "        36: 'О любви',\n",
    "        37: 'Короткий вопрос, недопонимание',\n",
    "        38: 'Короткий вопрос обыденный',\n",
    "        39: 'Удивление',\n",
    "        40: 'Длинное рассуждение',\n",
    "        41: 'Жених, невеста',\n",
    "        42: 'О времени',\n",
    "        43: 'Друзья',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "v0477vni71fw1pfgleoul"
   },
   "outputs": [],
   "source": [
    "def ngrams_from_vector(vec, n=3):\n",
    "    return [vec[i: i+n] for i in range(len(vec)-n + 1)]\n",
    "\n",
    "def ngrams_from_vector2(vec, text, n=3):\n",
    "    return [(vec[i: i+n], text[i: i+n]) for i in range(len(vec)-n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "w8jfuo11kah93ot5qiblqm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 785.46it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_vecs = []\n",
    "cluster_vecs_text_no = []\n",
    "cluster_vecs_text = []\n",
    "for i, drama in enumerate(tqdm(dramas_texts)):\n",
    "    for part in drama:\n",
    "        clusters = []\n",
    "        texts = []\n",
    "        for person, sent in part:\n",
    "            if sent not in sentence_to_vector:\n",
    "                continue # Skip empty or too long texts\n",
    "            sent_vec = sentence_to_vector[sent]\n",
    "            clusters.append(sent_vec)\n",
    "            texts.append(sent)\n",
    "        cluster_vecs.append(clusters)\n",
    "        cluster_vecs_text_no.append(i)\n",
    "        cluster_vecs_text.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "hs9gywsxcg9xh33i3nd59p"
   },
   "outputs": [],
   "source": [
    "cluster_vecs_text_no_train, _ = train_test_split(list(set(cluster_vecs_text_no)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "w1mgdhuaahmbik1uaq3i9o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5869, 5869, 5869)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_vecs), len(cluster_vecs_text_no), len(cluster_vecs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "hv63p6c6ukd24ihgcgcrd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5869/5869 [01:25<00:00, 68.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131153\n"
     ]
    }
   ],
   "source": [
    "X_lstm_train, X_lstm_test, y_lstm_train, y_lstm_test = [], [], [],[]\n",
    "X_text_train = []\n",
    "cl_lstm_train, cl_lstm_test = [], []\n",
    "\n",
    "for vec, text_no, text in zip(tqdm(cluster_vecs), cluster_vecs_text_no, cluster_vecs_text):\n",
    "    if len(vec) < 3:\n",
    "        continue\n",
    "    for ngrams, texxts in ngrams_from_vector2(vec, text, n=8):\n",
    "        X_lstm = ngrams[:3].copy()\n",
    "        y_lstm = ngrams[3].copy()\n",
    "        cl_lstm = cluster_model_kmeans.predict(np.array(ngrams[3:]))\n",
    "        if text_no in cluster_vecs_text_no_train:\n",
    "            X_lstm_train.append(X_lstm)\n",
    "            y_lstm_train.append(y_lstm)\n",
    "            cl_lstm_train.append(cl_lstm)\n",
    "            X_text_train.append(texxts)\n",
    "        else:\n",
    "            X_lstm_test.append(X_lstm)\n",
    "            y_lstm_test.append(y_lstm)\n",
    "            cl_lstm_test.append(cl_lstm)\n",
    "\n",
    "X_lstm_train = np.array(X_lstm_train)\n",
    "X_lstm_test = np.array(X_lstm_test)\n",
    "y_lstm_train = np.array(y_lstm_train)\n",
    "y_lstm_test = np.array(y_lstm_test)\n",
    "cl_lstm_train = np.array(cl_lstm_train)\n",
    "cl_lstm_test = np.array(cl_lstm_test)\n",
    "print(len(X_lstm_train))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "2yiixs1479k87yhp83yiqi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(\n",
    "    (X_lstm_train, y_lstm_train, X_lstm_test, y_lstm_test, cl_lstm_train, cl_lstm_test),\n",
    "    '03_train_recurrent3.pkl.zip'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "21bad8dc-18cc-475e-b953-a42d85d7ad5e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
